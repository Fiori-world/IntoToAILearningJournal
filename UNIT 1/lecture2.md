**Lecture 2**

bias- computers are not bias they are programed by developers who are bias
so ai is bias just because the people who made it 


context window -chat gpt was trained only  known
generative ai gives a promt of any thing and outputs a response
hallucination it makes things up usually an error 
large language model (llm)
meta prompt/system prompt - promts before you even joined the text
prompt engineering 
there is a way to talk to the ai to get better results
 temperature ai 
tokenizer
